# üìö H∆Ø·ªöNG D·∫™N T·∫†O TRUY·ªÜN TRANH - K·ª∂ NI·ªÜM 80 NƒÇM QU·ªêC KH√ÅNH

## üìã T·ªîNG QUAN D·ª∞ √ÅN

**Ch·ªß ƒë·ªÅ:** T·ªïng k·∫øt, ph√¢n t√≠ch c√°c ho·∫°t ƒë·ªông ch√†o m·ª´ng k·ª∑ ni·ªám **80 nƒÉm Qu·ªëc kh√°nh 2/9/2025** (to√†n qu·ªëc)

**S·∫£n ph·∫©m:** Truy·ªán tranh (comic) 5-10 trang, k√≠ch th∆∞·ªõc A4, c√≥ b√¨a, xu·∫•t b·∫£n d·∫°ng SVG vector

**M·ª•c ti√™u:** S√°ng t·∫°o truy·ªán tranh m·ªõi, khai th√°c ·∫£nh h·ª£p l·ªá l√†m n·ªÅn/khung c·∫£nh, ch√®n thuy·∫øt minh-h·ªôi tho·∫°i mang t√≠nh gi√°o d·ª•c-truy·ªÅn c·∫£m h·ª©ng

---

## ‚ö†Ô∏è Y√äU C·∫¶U TU√ÇN TH·ª¶ TUY·ªÜT ƒê·ªêI

### üñºÔ∏è Ngu·ªìn ·∫£nh h·ª£p l·ªá
* ·∫¢nh **ch·ªâ** ƒë∆∞·ª£c khai th√°c t·ª´ 3 ngu·ªìn ch√≠nh th·ª©c:
  - **dangcongsan.vn** (B√°o ƒê·∫£ng C·ªông S·∫£n)
  - **baochinhphu.vn** (B√°o Ch√≠nh Ph·ªß) 
  - **vtv.vn** (ƒê√†i Truy·ªÅn h√¨nh Vi·ªát Nam)
* **Kh√¥ng** s·ª≠ d·ª•ng ·∫£nh t·ª´ b·∫•t k·ª≥ ngu·ªìn n√†o kh√°c
* Ph·∫£i l∆∞u metadata ƒë·∫ßy ƒë·ªß (URL ngu·ªìn, ng√†y truy c·∫≠p, credit)

### üé® Quy ƒë·ªãnh ƒë·ªì h·ªça
* **Kh√¥ng** s·ª≠ d·ª•ng **video** khai th√°c tr√™n Internet
* Truy·ªán tranh ƒë∆∞·ª£c t·∫°o t·ª´:
  - ·∫¢nh h·ª£p l·ªá t·ª´ 3 ngu·ªìn l√†m n·ªÅn/khung c·∫£nh
  - ƒê·ªì h·ªça/hi·ªáu ·ª©ng t·ª± t·∫°o (SVG)
  - Text v√† dialogue t·ª± sinh

### üèóÔ∏è Ki·∫øn tr√∫c k·ªπ thu·∫≠t
* Th√†nh ph·∫©m **serverless** (kh√¥ng backend)
* Ch·∫°y ho√†n to√†n trong m√¥i tr∆∞·ªùng Cursor
* **Ch·ªâ** d√πng c√°c API ƒë∆∞·ª£c cung c·∫•p:
  - **Text Generation**: Gemini 2.5 Pro/Flash
  - **Image Generation**: Imagen-4 (ch·ªâ cho icon/ƒë·ªì h·ªça b·ªï tr·ª£)
  - **Text-to-Speech**: gemini-2.5-pro-preview-tts (n·∫øu c·∫ßn)

### üìù N·ªôi dung v√† th√¥ng ƒëi·ªáp
* N·ªôi dung b·∫±ng **ti·∫øng Vi·ªát**, trang tr·ªçng
* Kh∆°i g·ª£i **t·ª± h√†o d√¢n t·ªôc**
* Nh·∫•n m·∫°nh **tr√°ch nhi·ªám c√¥ng d√¢n**
* T√¥ng: **trang tr·ªçng ‚Äì ·∫•m √°p ‚Äì truy·ªÅn c·∫£m h·ª©ng**

---

## üóÇÔ∏è C·∫§U TR√öC TH·ª¶ M·ª§C D·ª∞ √ÅN

```
project/
‚îú‚îÄ .env                      # API_KEY (kh√¥ng commit)
‚îú‚îÄ sources/
‚îÇ   ‚îî‚îÄ links.txt            # Danh s√°ch URL b√†i vi·∫øt t·ª´ 3 ngu·ªìn
‚îú‚îÄ public/
‚îÇ   ‚îú‚îÄ assets/              # ·∫¢nh t·∫£i v·ªÅ + images.json (metadata)
‚îÇ   ‚îî‚îÄ voice/               # File MP3 TTS (n·∫øu c·∫ßn)
‚îú‚îÄ out/
‚îÇ   ‚îú‚îÄ story.json           # C·ªët truy·ªán + tho·∫°i (JSON)
‚îÇ   ‚îî‚îÄ story_full.txt       # To√†n b·ªô n·ªôi dung truy·ªán
‚îú‚îÄ dist/
‚îÇ   ‚îî‚îÄ news_80nam_1080p.mp4 # Video xu·∫•t ra (ƒê·ªÅ 1)
‚îú‚îÄ comic/                   # C√°c trang SVG A4
‚îú‚îÄ crawler.py               # Tool t·∫£i ·∫£nh t·ª´ 3 ngu·ªìn
‚îú‚îÄ gen_script.py            # Tool sinh k·ªãch b·∫£n (ƒê·ªÅ 1)
‚îú‚îÄ tts.py                   # Tool t·∫°o gi·ªçng ƒë·ªçc (ƒê·ªÅ 1)
‚îú‚îÄ make_video.py            # Tool d·ª±ng video (ƒê·ªÅ 1)
‚îú‚îÄ gen_story.py             # Tool sinh c·ªët truy·ªán
‚îî‚îÄ make_comic.py            # Tool t·∫°o truy·ªán tranh SVG
```

---

## üîß THI·∫æT L·∫¨P M√îI TR∆Ø·ªúNG

### üìÅ T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c
```bash
mkdir -p project/{sources,public/assets,public/voice,out,dist,comic}
```

### üîë C·∫•u h√¨nh API Key
T·∫°o file `.env`:
```bash
API_KEY=sk-xxxxxx
```

### üêç C√†i ƒë·∫∑t Python dependencies
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install requests beautifulsoup4 pillow pydub moviepy imageio-ffmpeg svgwrite
# (tu·ª≥ ch·ªçn n·∫øu render PNG t·ª´ SVG): pip install cairosvg
```

---

## üì∞ B∆Ø·ªöC 1: CHU·∫®N B·ªä DANH S√ÅCH NGU·ªíN B√ÄI VI·∫æT

### üéØ M·ª•c ti√™u
Thu th·∫≠p URL t·ª´ 3 ngu·ªìn ch√≠nh th·ª©c v·ªÅ c√°c ho·∫°t ƒë·ªông k·ª∑ ni·ªám 80 nƒÉm Qu·ªëc kh√°nh

### üìù Th·ª±c hi·ªán
1. M·ªü file `sources/links.txt`
2. **Ch·ªâ d√°n** c√°c URL t·ª´ 3 ngu·ªìn h·ª£p l·ªá:
   - `https://dangcongsan.vn/...`
   - `https://baochinhphu.vn/...`
   - `https://vtv.vn/...`

### üîç G·ª£i √Ω ph·∫°m vi t√¨m ki·∫øm
T√¨m ki·∫øm trong c√°c chuy√™n m·ª•c:
- **Ch√≠nh tr·ªã**: L·ªÖ k·ª∑ ni·ªám, di·ªÖu binh, th∆∞·ª£ng c·ªù
- **S·ª± ki·ªán**: Ch∆∞∆°ng tr√¨nh ngh·ªá thu·∫≠t, tri·ªÉn l√£m
- **X√£ h·ªôi**: Ho·∫°t ƒë·ªông tri √¢n, an sinh x√£ h·ªôi
- **Gi√°o d·ª•c**: Thi ƒëua 80 nƒÉm, gi√°o d·ª•c truy·ªÅn th·ªëng
- **VƒÉn h√≥a**: Ch∆∞∆°ng tr√¨nh ngh·ªá thu·∫≠t, √°nh s√°ng

### üìä Y√™u c·∫ßu s·ªë l∆∞·ª£ng
- T·ªëi thi·ªÉu: **15-20 URL** t·ª´ m·ªói ngu·ªìn
- T·ªïng c·ªông: **45-60 URL** ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªß ·∫£nh ch·∫•t l∆∞·ª£ng

---

## üñºÔ∏è B∆Ø·ªöC 2: T·∫¢I ·∫¢NH H·ª¢P L·ªÜ V√Ä L∆ØU METADATA

### üéØ M·ª•c ti√™u
T·ª± ƒë·ªông t·∫£i ·∫£nh t·ª´ c√°c URL ƒë√£ chu·∫©n b·ªã v√† l∆∞u metadata ƒë·∫ßy ƒë·ªß

### üíª T·∫°o file `crawler.py`

```python
# crawler.py
import os, json, re, time, urllib.parse, requests
from bs4 import BeautifulSoup

BASE_DIR = "public/assets"
os.makedirs(BASE_DIR, exist_ok=True)

# Danh s√°ch domain ƒë∆∞·ª£c ph√©p
SITES = ["dangcongsan.vn", "baochinhphu.vn", "vtv.vn"]

def in_whitelist(url):
    """Ki·ªÉm tra URL c√≥ thu·ªôc 3 ngu·ªìn ƒë∆∞·ª£c ph√©p kh√¥ng"""
    host = urllib.parse.urlparse(url).netloc
    return any(host.endswith(s) for s in SITES)

def fetch_images_from_page(page_url):
    """Tr√≠ch xu·∫•t t·∫•t c·∫£ ·∫£nh t·ª´ m·ªôt trang web"""
    try:
        r = requests.get(page_url, timeout=30)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        imgs = set()
        
        # L·∫•y og:image (·∫£nh ƒë·∫°i di·ªán)
        for tag in soup.select('meta[property="og:image"]'):
            if tag.get("content"):
                imgs.add(urllib.parse.urljoin(page_url, tag["content"]))
        
        # L·∫•y t·∫•t c·∫£ th·∫ª img
        for img_tag in soup.find_all("img"):
            src = img_tag.get("data-src") or img_tag.get("src")
            if src:
                imgs.add(urllib.parse.urljoin(page_url, src))
        
        return list(imgs)
    except Exception as e:
        print(f"L·ªói khi t·∫£i trang {page_url}: {e}")
        return []

def sanitize_filename(name):
    """L√†m s·∫°ch t√™n file"""
    name = name.strip().split("?")[0]
    name = os.path.basename(name)
    return re.sub(r'[^a-zA-Z0-9._-]+','_', name) or f"img_{int(time.time()*1000)}.jpg"

def download_image(url, save_dir=BASE_DIR):
    """T·∫£i ·∫£nh v·ªÅ m√°y"""
    try:
        filename = sanitize_filename(url)
        if not filename.lower().endswith((".jpg",".jpeg",".png",".webp")):
            filename += ".jpg"
        
        filepath = os.path.join(save_dir, filename)
        
        with requests.get(url, stream=True, timeout=60) as r:
            r.raise_for_status()
            with open(filepath, "wb") as f:
                for chunk in r.iter_content(8192):
                    if chunk:
                        f.write(chunk)
        
        return filepath
    except Exception as e:
        print(f"L·ªói khi t·∫£i ·∫£nh {url}: {e}")
        return None

def run():
    """H√†m ch√≠nh th·ª±c hi·ªán crawler"""
    links_path = "sources/links.txt"
    if not os.path.exists(links_path):
        print("‚ùå Thi·∫øu file sources/links.txt")
        return
    
    with open(links_path, "r", encoding="utf-8") as f:
        pages = [line.strip() for line in f if line.strip()]

    downloaded_images = []
    
    for page_url in pages:
        if not in_whitelist(page_url):
            print(f"‚ö†Ô∏è B·ªè qua URL kh√¥ng h·ª£p l·ªá: {page_url}")
            continue
        
        print(f"üîç ƒêang x·ª≠ l√Ω: {page_url}")
        images = fetch_images_from_page(page_url)
        
        for img_url in images:
            try:
                filepath = download_image(img_url)
                if filepath:
                    downloaded_images.append({
                        "local_path": filepath.replace("\\","/"),
                        "source_page": page_url,
                        "image_url": img_url,
                        "credit": page_url,
                        "accessed_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                        "file_size": os.path.getsize(filepath)
                    })
                    print(f"‚úÖ ƒê√£ l∆∞u: {filepath}")
            except Exception as e:
                print(f"‚ùå L·ªói t·∫£i ·∫£nh {img_url}: {e}")

    # L∆∞u metadata
    with open(os.path.join(BASE_DIR, "images.json"), "w", encoding="utf-8") as f:
        json.dump(downloaded_images, f, ensure_ascii=False, indent=2)
    
    print(f"üéâ Ho√†n th√†nh! ƒê√£ t·∫£i {len(downloaded_images)} ·∫£nh ‚Üí public/assets/images.json")

if __name__ == "__main__":
    run()
```

### üöÄ Ch·∫°y crawler
```bash
python crawler.py
```

### ‚úÖ Ki·ªÉm tra k·∫øt qu·∫£
- File `public/assets/images.json` ch·ª©a metadata
- Th∆∞ m·ª•c `public/assets/` ch·ª©a c√°c file ·∫£nh
- T·ªëi thi·ªÉu c·∫ßn **20-30 ·∫£nh** ch·∫•t l∆∞·ª£ng ƒë·ªÉ t·∫°o truy·ªán tranh

---

## üìñ B∆Ø·ªöC 3: SINH C·ªêT TRUY·ªÜN + THO·∫†I (JSON)

### üéØ M·ª•c ti√™u
T·∫°o c·ªët truy·ªán h·∫•p d·∫´n v·ªõi c·∫•u tr√∫c r√µ r√†ng, ph√π h·ª£p v·ªõi ƒë·ªãnh d·∫°ng truy·ªán tranh

### üíª T·∫°o file `gen_story.py`

```python
# gen_story.py
from openai import OpenAI
import os, json, re

# Kh·ªüi t·∫°o client
client = OpenAI(
    api_key=os.getenv("API_KEY"), 
    base_url="https://api.thucchien.ai"
)

# Prompt chi ti·∫øt cho AI
PROMPT = {
    "role": "user",
    "content": (
        "S√°ng t·∫°o truy·ªán tranh ch·ªß ƒë·ªÅ 80 nƒÉm Qu·ªëc kh√°nh 2/9/2025, ti·∫øng Vi·ªát, 6‚Äì8 trang (bao g·ªìm 1 trang b√¨a).\n"
        "Tr·∫£ v·ªÅ JSON: {title, pages:[{page_no, kind: 'cover'|'story', page_title, narration, panels:[{role:'caption'|'dialogue', speaker?, text}]}]}.\n"
        "T√¥ng: trang tr·ªçng ‚Äì ·∫•m √°p ‚Äì truy·ªÅn c·∫£m h·ª©ng, n√™u gi√° tr·ªã ƒë·ªôc l·∫≠p ‚Äì t·ª± do ‚Äì ƒëo√†n k·∫øt ‚Äì ƒë·ªïi m·ªõi.\n"
        "Kh√¥ng n√™u chi ti·∫øt ch∆∞a ch·∫Øc ch·∫Øn. L·ªùi ng·∫Øn g·ªçn, ph√π h·ª£p b·ªë c·ª•c tranh.\n"
        "C·∫•u tr√∫c ƒë·ªÅ xu·∫•t:\n"
        "- Trang 1: B√¨a (cover) - Ti√™u ƒë·ªÅ + h√¨nh ·∫£nh n·ªïi b·∫≠t\n"
        "- Trang 2-3: L·ªãch s·ª≠ - T√≥m t·∫Øt 80 nƒÉm qua\n"
        "- Trang 4-5: Hi·ªán t·∫°i - C√°c ho·∫°t ƒë·ªông k·ª∑ ni·ªám\n"
        "- Trang 6-7: T∆∞∆°ng lai - Kh√°t v·ªçng ph√°t tri·ªÉn\n"
        "- Trang 8: K·∫øt - Th√¥ng ƒëi·ªáp ƒëo√†n k·∫øt\n"
        "M·ªói panel c√≥ t·ªëi ƒëa 2-3 c√¢u, d·ªÖ ƒë·ªçc, c√≥ √Ω nghƒ©a s√¢u s·∫Øc."
    )
}

def generate_story():
    """Sinh c·ªët truy·ªán b·∫±ng AI"""
    try:
        print("ü§ñ ƒêang sinh c·ªët truy·ªán...")
        response = client.chat.completions.create(
            model="gemini-2.5-pro",
            messages=[PROMPT]
        )
        
        text = response.choices[0].message.content
        print("‚úÖ AI ƒë√£ sinh c·ªët truy·ªán")
        
        # L∆∞u to√†n b·ªô response
        os.makedirs("out", exist_ok=True)
        with open("out/story_full.txt", "w", encoding="utf-8") as f:
            f.write(text)
        
        # Tr√≠ch xu·∫•t JSON
        json_match = re.search(r"\{[\s\S]*\}", text)
        if not json_match:
            raise SystemExit("‚ùå Kh√¥ng t√¨m th·∫•y JSON trong ph·∫£n h·ªìi")
        
        story_data = json.loads(json_match.group(0))
        
        # L∆∞u JSON
        with open("out/story.json", "w", encoding="utf-8") as f:
            json.dump(story_data, f, ensure_ascii=False, indent=2)
        
        print("‚úÖ story.json s·∫µn s√†ng")
        return story_data
        
    except Exception as e:
        print(f"‚ùå L·ªói khi sinh c·ªët truy·ªán: {e}")
        return None

if __name__ == "__main__":
    generate_story()
```

### üöÄ Ch·∫°y story generator
```bash
python gen_story.py
```

### üìã C·∫•u tr√∫c truy·ªán mong ƒë·ª£i
```json
{
  "title": "H√†nh Tr√¨nh 80 NƒÉm - T·ª± H√†o Vi·ªát Nam",
  "pages": [
    {
      "page_no": 1,
      "kind": "cover",
      "page_title": "K·ª∑ Ni·ªám 80 NƒÉm Qu·ªëc Kh√°nh",
      "narration": "M·ªôt h√†nh tr√¨nh vƒ© ƒë·∫°i c·ªßa d√¢n t·ªôc Vi·ªát Nam",
      "panels": []
    },
    {
      "page_no": 2,
      "kind": "story",
      "page_title": "L·ªãch S·ª≠ H√†o H√πng",
      "narration": "T·ª´ ng√†y 2/9/1945 ƒë·∫øn nay...",
      "panels": [
        {
          "role": "caption",
          "text": "Ng√†y 2/9/1945, Ch·ªß t·ªãch H·ªì Ch√≠ Minh ƒë·ªçc Tuy√™n ng√¥n ƒê·ªôc l·∫≠p"
        },
        {
          "role": "dialogue",
          "speaker": "B√°c H·ªì",
          "text": "N∆∞·ªõc Vi·ªát Nam c√≥ quy·ªÅn h∆∞·ªüng t·ª± do v√† ƒë·ªôc l·∫≠p"
        }
      ]
    }
  ]
}
```

---

## üé® B∆Ø·ªöC 4: D·ª∞NG TRANG A4 (SVG) T·ª™ ·∫¢NH H·ª¢P L·ªÜ + THO·∫†I

### üéØ M·ª•c ti√™u
T·∫°o truy·ªán tranh chuy√™n nghi·ªáp v·ªõi ƒë·ªãnh d·∫°ng SVG vector, c√≥ th·ªÉ in ·∫•n

### üíª T·∫°o file `make_comic.py`

```python
# make_comic.py
import os, json, random, math
import svgwrite
from PIL import Image

# C·∫•u h√¨nh A4
W_mm, H_mm = 210, 297  # A4 mm
DPI = 300
PX_W, PX_H = int(W_mm/25.4*DPI), int(H_mm/25.4*DPI)
MARGIN = 40  # px

def load_data():
    """T·∫£i d·ªØ li·ªáu c·∫ßn thi·∫øt"""
    with open("public/assets/images.json", "r", encoding="utf-8") as f:
        images = json.load(f)
    
    with open("out/story.json", "r", encoding="utf-8") as f:
        story = json.load(f)
    
    return images, story

def choose_images(images, count):
    """Ch·ªçn ·∫£nh ng·∫´u nhi√™n"""
    random.shuffle(images)
    selected = []
    for img in images:
        path = img["local_path"]
        if os.path.exists(path):
            selected.append(path)
            if len(selected) >= count:
                break
    return selected

def add_speech_bubble(dwg, group, x, y, w, h, text, tail_to=None):
    """Th√™m bong b√≥ng tho·∫°i"""
    # Bong b√≥ng: h√¨nh ch·ªØ nh·∫≠t bo g√≥c + ƒëu√¥i tam gi√°c
    radius = 18
    group.add(dwg.rect(
        insert=(x, y), 
        size=(w, h), 
        rx=radius, 
        ry=radius, 
        fill='white', 
        stroke='black', 
        stroke_width=2, 
        opacity=0.92
    ))
    
    # ƒêu√¥i bong b√≥ng
    if tail_to:
        tx, ty = tail_to
        group.add(dwg.polygon(
            points=[(x+w*0.3, y+h), (x+w*0.35, y+h+22), (tx, ty)], 
            fill='white', 
            stroke='black', 
            stroke_width=2
        ))
    
    # Text (SVG native)
    text_element = dwg.text("", insert=(x+16, y+34), fill='black', font_size=24, font_family='system-ui')
    
    # Wrap text theo ƒë·ªô d√†i k√Ω t·ª±
    line = ""
    max_chars = int((w-32)/12)
    
    for word in text.split():
        if len(line) + len(word) + 1 > max_chars:
            text_element.add(dwg.tspan(line, x=[x+16], dy=[28]))
            line = word
        else:
            line = (line + " " + word).strip()
    
    if line:
        text_element.add(dwg.tspan(line, x=[x+16], dy=[28]))
    
    group.add(text_element)

def create_cover_page(dwg, page_data, images):
    """T·∫°o trang b√¨a"""
    # N·ªÅn
    dwg.add(dwg.rect(insert=(0, 0), size=(PX_W, PX_H), fill="#f7f7f7"))
    
    # Ti√™u ƒë·ªÅ trang
    title = page_data.get("page_title", "Trang b√¨a")
    dwg.add(dwg.text(
        title, 
        insert=(MARGIN, MARGIN+10), 
        font_size=36, 
        font_family='system-ui', 
        fill='#111'
    ))
    
    # ·∫¢nh n·ªÅn ch√≠nh
    selected_images = choose_images(images, 1)
    if selected_images:
        img_path = selected_images[0]
        try:
            img = Image.open(img_path)
            iw, ih = img.size
            
            # Fit v√†o khung l·ªõn
            box_w, box_h = PX_W - 2*MARGIN, PX_H - 3*MARGIN
            scale = min(box_w/iw, box_h/ih)
            rw, rh = int(iw*scale), int(ih*scale)
            x = (PX_W - rw)//2
            y = (PX_H - rh)//2
            
            dwg.add(dwg.image(href=img_path, insert=(x, y), size=(rw, rh)))
        except Exception as e:
            print(f"L·ªói khi t·∫£i ·∫£nh {img_path}: {e}")
    
    # Text k·ª∑ ni·ªám
    dwg.add(dwg.text(
        "K·ª∑ ni·ªám 80 nƒÉm Qu·ªëc kh√°nh 2/9/2025", 
        insert=(MARGIN, PX_H-MARGIN), 
        font_size=28, 
        fill='#c00'
    ))

def create_story_page(dwg, page_data, images):
    """T·∫°o trang n·ªôi dung"""
    # N·ªÅn
    dwg.add(dwg.rect(insert=(0, 0), size=(PX_W, PX_H), fill="#f7f7f7"))
    
    # Ti√™u ƒë·ªÅ trang
    title = page_data.get("page_title", "Trang")
    dwg.add(dwg.text(
        title, 
        insert=(MARGIN, MARGIN+10), 
        font_size=36, 
        font_family='system-ui', 
        fill='#111'
    ))
    
    # B·ªë c·ª•c 2-4 khung linh ho·∫°t
    panels = page_data.get("panels", [])
    panel_count = min(4, max(2, len(panels)))
    selected_images = choose_images(images, panel_count)
    
    # T√≠nh to√°n layout
    cols = 2 if panel_count >= 2 else 1
    rows = math.ceil(panel_count/cols)
    padding = 16
    
    panel_w = (PX_W - 2*MARGIN - (cols-1)*padding)//cols
    panel_h = (PX_H - 2*MARGIN - 60 - (rows-1)*padding)//rows
    
    # T·∫°o c√°c panel
    for i in range(panel_count):
        row = i // cols
        col = i % cols
        
        x = MARGIN + col*(panel_w + padding)
        y = MARGIN + 40 + row*(panel_h + padding)
        
        # Khung panel
        dwg.add(dwg.rect(
            insert=(x, y), 
            size=(panel_w, panel_h), 
            fill='white', 
            stroke='#ddd'
        ))
        
        # ·∫¢nh n·ªÅn panel
        if i < len(selected_images):
            img_path = selected_images[i]
            dwg.add(dwg.image(
                href=img_path, 
                insert=(x, y), 
                size=(panel_w, panel_h), 
                preserveAspectRatio='xMidYMid slice'
            ))
        
        # Bong b√≥ng tho·∫°i n·∫øu c√≥ text
        if i < len(panels):
            panel_text = panels[i].get('text', '')
            if panel_text:
                bubble_x = x + 16
                bubble_y = y + 16
                bubble_w = panel_w - 32
                bubble_h = 110
                
                add_speech_bubble(
                    dwg, dwg, 
                    bubble_x, bubble_y, bubble_w, bubble_h, 
                    panel_text, 
                    tail_to=(x + panel_w*0.8, y + bubble_h + 20)
                )

def create_comic_pages():
    """T·∫°o t·∫•t c·∫£ trang truy·ªán tranh"""
    images, story = load_data()
    
    os.makedirs("comic", exist_ok=True)
    
    for page_data in story.get("pages", []):
        page_no = page_data.get("page_no", 1)
        kind = page_data.get("kind", "story")
        
        # T·∫°o SVG
        dwg = svgwrite.Drawing(
            filename=f"comic/page_{page_no:02d}.svg", 
            size=(f"{PX_W}px", f"{PX_H}px")
        )
        
        if kind == 'cover':
            create_cover_page(dwg, page_data, images)
        else:
            create_story_page(dwg, page_data, images)
        
        # Footer credit + s·ªë trang
        footer = f"Ngu·ªìn ·∫£nh: dangcongsan.vn ¬∑ baochinhphu.vn ¬∑ vtv.vn  ‚Äî  Trang {page_no}"
        dwg.add(dwg.text(
            footer, 
            insert=(MARGIN, PX_H-MARGIN/2), 
            font_size=18, 
            fill='#555'
        ))
        
        dwg.save()
        print(f"‚úÖ ƒê√£ t·∫°o: {dwg.filename}")

def main():
    """H√†m ch√≠nh"""
    print("üé® B·∫Øt ƒë·∫ßu t·∫°o truy·ªán tranh...")
    create_comic_pages()
    print("üéâ Ho√†n th√†nh! Truy·ªán tranh ƒë√£ l∆∞u trong th∆∞ m·ª•c comic/")

if __name__ == "__main__":
    main()
```

### üöÄ Ch·∫°y comic generator
```bash
python make_comic.py
```

### üìä K·∫øt qu·∫£
- File `comic/page_01.svg` ‚Ä¶ `page_N.svg` (A4, vector, in ·∫•n ƒë∆∞·ª£c)
- ƒê·ªãnh d·∫°ng SVG vector, ch·∫•t l∆∞·ª£ng cao
- C√≥ th·ªÉ in ·ªü b·∫•t k·ª≥ k√≠ch th∆∞·ªõc n√†o

---

## üñºÔ∏è B∆Ø·ªöC 5: CHUY·ªÇN ƒê·ªîI SANG PNG (TU·ª≤ CH·ªåN)

### üéØ M·ª•c ti√™u
T·∫°o file PNG ƒë·ªÉ xem tr∆∞·ªõc v√† chia s·∫ª d·ªÖ d√†ng

### üíª Script chuy·ªÉn ƒë·ªïi

```python
# convert_to_png.py
import glob
import cairosvg

def convert_svg_to_png():
    """Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ SVG sang PNG"""
    svg_files = sorted(glob.glob('comic/page_*.svg'))
    
    for svg_file in svg_files:
        png_file = svg_file.replace('.svg', '.png')
        try:
            cairosvg.svg2png(
                url=svg_file, 
                write_to=png_file, 
                output_width=1240  # ƒê·ªô ph√¢n gi·∫£i xem nhanh
            )
            print(f"‚úÖ ƒê√£ chuy·ªÉn: {png_file}")
        except Exception as e:
            print(f"‚ùå L·ªói chuy·ªÉn ƒë·ªïi {svg_file}: {e}")

if __name__ == "__main__":
    convert_svg_to_png()
```

### üöÄ Ch·∫°y converter
```bash
pip install cairosvg
python convert_to_png.py
```

---

## ‚úÖ CHECKLIST NGHI·ªÜM THU

### üìö C·∫•u tr√∫c truy·ªán tranh
- [ ] 5‚Äì10 trang, c√≥ **1 trang b√¨a**
- [ ] K√≠ch th∆∞·ªõc **A4** (SVG vector), c√≥ th·ªÉ in
- [ ] B·ªë c·ª•c r√µ r√†ng, d·ªÖ ƒë·ªçc

### üñºÔ∏è Ngu·ªìn ·∫£nh v√† metadata
- [ ] ·∫¢nh ch·ªâ t·ª´ 3 ngu·ªìn: dangcongsan.vn, baochinhphu.vn, vtv.vn
- [ ] C√≥ credit footer tr√™n m·ªói trang
- [ ] Metadata ƒë·∫ßy ƒë·ªß trong `images.json`

### üìù N·ªôi dung v√† th√¥ng ƒëi·ªáp
- [ ] L·ªùi/narration ng·∫Øn g·ªçn, gi√†u √Ω nghƒ©a
- [ ] Truy·ªÅn c·∫£m h·ª©ng, t√¥n vinh gi√° tr·ªã ƒë·ªôc l·∫≠p ‚Äì t·ª± do ‚Äì ƒëo√†n k·∫øt
- [ ] Kh√¥ng d√πng video/clip ngo√†i
- [ ] Ch·ªâ ·∫£nh tƒ©nh h·ª£p l·ªá v√† ƒë·ªì h·ªça t·ª± t·∫°o

### üé® Ch·∫•t l∆∞·ª£ng thi·∫øt k·∫ø
- [ ] Bong b√≥ng tho·∫°i r√µ r√†ng, d·ªÖ ƒë·ªçc
- [ ] ·∫¢nh n·ªÅn ch·∫•t l∆∞·ª£ng cao
- [ ] M√†u s·∫Øc ph√π h·ª£p v·ªõi ch·ªß ƒë·ªÅ
- [ ] Layout c√¢n ƒë·ªëi, chuy√™n nghi·ªáp

---

## üöÄ L·ªÜNH CH·∫†Y T√ìM T·∫ÆT

```bash
# 1. T·∫£i ·∫£nh t·ª´ 3 ngu·ªìn h·ª£p l·ªá
python crawler.py

# 2. Sinh c·ªët truy·ªán
python gen_story.py

# 3. T·∫°o truy·ªán tranh SVG
python make_comic.py

# 4. (Tu·ª≥ ch·ªçn) Chuy·ªÉn sang PNG
python convert_to_png.py
```

---

## üí° M·∫∏O HO√ÄN THI·ªÜN

### üéØ T·ªëi ∆∞u n·ªôi dung
- M·ªói panel t·ªëi ƒëa 2-3 c√¢u
- L·ªùi tho·∫°i ng·∫Øn g·ªçn, s√∫c t√≠ch
- C√¢n b·∫±ng gi·ªØa narration v√† dialogue

### üñºÔ∏è C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ·∫£nh
- ∆Øu ti√™n ·∫£nh c√≥ ƒë·ªô ph√¢n gi·∫£i cao
- Ch·ªçn ·∫£nh ph√π h·ª£p v·ªõi n·ªôi dung t·ª´ng trang
- ƒê·∫£m b·∫£o ·∫£nh kh√¥ng b·ªã m·ªù ho·∫∑c pixelated

### üé® N√¢ng cao thi·∫øt k·∫ø
- S·ª≠ d·ª•ng m√†u s·∫Øc nh·∫•t qu√°n
- T·∫°o bong b√≥ng tho·∫°i ƒëa d·∫°ng
- Th√™m hi·ªáu ·ª©ng shadow cho text

---

## üéØ TH√îNG ƒêI·ªÜP TRUNG T√ÇM

### üáªüá≥ Tinh th·∫ßn y√™u n∆∞·ªõc
- T√¥n vinh **√Ω ch√≠ ƒë·ªôc l·∫≠p ‚Äì t·ª± do**
- Bi·∫øt ∆°n c√°c th·∫ø h·ªá cha anh
- Kh∆°i d·∫≠y **kh√°t v·ªçng ph√°t tri·ªÉn** ph·ªìn vinh, h·∫°nh ph√∫c

### ü§ù ƒê·∫°i ƒëo√†n k·∫øt d√¢n t·ªôc
- Nh·∫•n m·∫°nh **s·ª©c m·∫°nh g·∫Øn k·∫øt** to√†n d√¢n t·ªôc
- VƒÉn h√≥a tri √¢n, tr√°ch nhi·ªám c√¥ng d√¢n
- Tinh th·∫ßn **ƒë·ªïi m·ªõi ‚Äì s√°ng t·∫°o**

### üìö Gi√° tr·ªã gi√°o d·ª•c
- Tr√°nh li·ªát k√™ kh√¥ khan
- ∆Øu ti√™n **gi√° tr·ªã ‚Äì √Ω nghƒ©a** c·ªßa ho·∫°t ƒë·ªông
- Lan t·ªèa nh√¢n √°i, h∆∞·ªõng t·ªõi t∆∞∆°ng lai

---

## üîí CAM K·∫æT TU√ÇN TH·ª¶

### ‚úÖ Ngu·ªìn ·∫£nh h·ª£p l·ªá
- Ch·ªâ d√πng ·∫£nh t·ª´ **dangcongsan.vn / baochinhphu.vn / vtv.vn**
- L∆∞u **images.json** l√†m b·∫±ng ch·ª©ng
- Ghi **credit** r√µ r√†ng tr√™n m·ªói trang

### ‚úÖ Kh√¥ng s·ª≠ d·ª•ng video ngo√†i
- Kh√¥ng t·∫£i/b√≥c t√°ch **video** t·ª´ Internet
- T·ª± t·∫°o ho√†n to√†n t·ª´ ·∫£nh tƒ©nh + ƒë·ªì h·ªça SVG

### ‚úÖ Serverless architecture
- To√†n b·ªô m√£ v√† s·∫£n ph·∫©m **serverless**
- T·ª± ch·∫°y trong m√¥i tr∆∞·ªùng Cursor
- Kh√¥ng ph·ª• thu·ªôc backend

---

## üìñ C·∫§U TR√öC TRUY·ªÜN ƒê·ªÄ XU·∫§T

### üìë Trang 1: B√¨a
- Ti√™u ƒë·ªÅ ch√≠nh: "K·ª∑ Ni·ªám 80 NƒÉm Qu·ªëc Kh√°nh"
- ·∫¢nh n·ªÅn: Qu·ªëc k·ª≥ ho·∫∑c l·ªÖ k·ª∑ ni·ªám
- Subtitle: "H√†nh Tr√¨nh T·ª± H√†o D√¢n T·ªôc"

### üìë Trang 2-3: L·ªãch S·ª≠
- T√≥m t·∫Øt 80 nƒÉm qua
- C√°c m·ªëc son l·ªãch s·ª≠
- Th√¥ng ƒëi·ªáp: "T·ª´ ƒë·ªôc l·∫≠p ƒë·∫øn ph·ªìn vinh"

### üìë Trang 4-5: Hi·ªán T·∫°i
- C√°c ho·∫°t ƒë·ªông k·ª∑ ni·ªám
- S·ª± tham gia c·ªßa nh√¢n d√¢n
- Th√¥ng ƒëi·ªáp: "ƒêo√†n k·∫øt, s√°ng t·∫°o, ph√°t tri·ªÉn"

### üìë Trang 6-7: T∆∞∆°ng Lai
- Kh√°t v·ªçng ph√°t tri·ªÉn
- Tr√°ch nhi·ªám th·∫ø h·ªá tr·∫ª
- Th√¥ng ƒëi·ªáp: "H∆∞·ªõng t·ªõi t∆∞∆°ng lai t∆∞∆°i s√°ng"

### üìë Trang 8: K·∫øt
- Th√¥ng ƒëi·ªáp ƒëo√†n k·∫øt
- L·ªùi k√™u g·ªçi h√†nh ƒë·ªông
- Th√¥ng ƒëi·ªáp: "Vi·ªát Nam m√£i m√£i t·ª± h√†o"

---

**üéâ Ch√∫c ƒë·ªôi thi ho√†n th√†nh t√°c ph·∫©m truy·ªán tranh ƒë·∫≠m ch·∫•t t·ª± h√†o, s√°ng t·∫°o m√† trang tr·ªçng ‚Äî lan t·ªèa tinh th·∫ßn 2/9! üáªüá≥**